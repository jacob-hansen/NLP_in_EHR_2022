{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jacobhansen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from text_processing import custom_tokenizer, custom_tokenizer_bow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "# warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobhansen/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arm', -1.173, 'areas']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'breaksys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(url)\n\u001b[1;32m      3\u001b[0m \u001b[39m# apply the custom tokenizer to the dataframe\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39mtokenized\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39;49m\u001b[39mX_train\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(custom_tokenizer_bow)\n\u001b[1;32m      5\u001b[0m \u001b[39m# create vocabulary of size 1000\u001b[39;00m\n\u001b[1;32m      6\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/pandas/core/series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4252\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4253\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m   4254\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4255\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4256\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4355\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4357\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/pandas/core/apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1043\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/pandas/core/apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1093\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1099\u001b[0m             values,\n\u001b[1;32m   1100\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1101\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1102\u001b[0m         )\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1105\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Fall 2022/6.8611/project_files/NLP_in_EHR_2022/text_processing.py:93\u001b[0m, in \u001b[0;36mcustom_tokenizer_bow\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     90\u001b[0m         bow_sents\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(sents[i]))\n\u001b[1;32m     92\u001b[0m \u001b[39mprint\u001b[39m(bow_sents)\n\u001b[0;32m---> 93\u001b[0m breaksys()\n\u001b[1;32m     94\u001b[0m \u001b[39m# flatten sents \u001b[39;00m\n\u001b[1;32m     95\u001b[0m return_sents \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breaksys' is not defined"
     ]
    }
   ],
   "source": [
    "url='https://raw.githubusercontent.com/jacob-hansen/NLP_in_EHR_2022/910d9f0fcfeab083dff53ea2e2969c175cc816a0/train.csv'\n",
    "train_df = pd.read_csv(url)\n",
    "# apply the custom tokenizer to the dataframe\n",
    "train_df['tokenized'] = train_df['X_train'].apply(custom_tokenizer_bow)\n",
    "# create vocabulary of size 1000\n",
    "vocab_size = 1000\n",
    "# create a tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(train_df['tokenized'])\n",
    "# encode training data set\n",
    "data = tokenizer.texts_to_sequences(train_df['tokenized'])\n",
    "# pad sequences\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), \n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "maxlen = np.max([len(x) for x in data])  # Maximum number of words in a sentence\n",
    "vocab_size = 1000 # size of the vocabulary\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "y = np.array(train_df['y_train'])\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split the train data into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 3s 24ms/step - loss: 0.5142 - accuracy: 0.7965 - val_loss: 0.5068 - val_accuracy: 0.8012\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.5109 - accuracy: 0.7975 - val_loss: 0.5004 - val_accuracy: 0.8012\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.5020 - accuracy: 0.8035 - val_loss: 0.5043 - val_accuracy: 0.8012\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.4988 - accuracy: 0.8030 - val_loss: 0.5001 - val_accuracy: 0.8012\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4976 - accuracy: 0.8030 - val_loss: 0.5016 - val_accuracy: 0.8012\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4979 - accuracy: 0.8024 - val_loss: 0.5035 - val_accuracy: 0.8012\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.5035 - accuracy: 0.7966 - val_loss: 0.5016 - val_accuracy: 0.8012\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.4999 - accuracy: 0.7982 - val_loss: 0.5043 - val_accuracy: 0.8012\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.4976 - accuracy: 0.8016 - val_loss: 0.5017 - val_accuracy: 0.8012\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.4834 - accuracy: 0.8041 - val_loss: 0.5080 - val_accuracy: 0.8012\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.4548 - accuracy: 0.7901 - val_loss: 0.5272 - val_accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.4339 - accuracy: 0.7977 - val_loss: 0.5563 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4112 - accuracy: 0.8095 - val_loss: 0.5876 - val_accuracy: 0.7994\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.4216 - accuracy: 0.7962 - val_loss: 0.6413 - val_accuracy: 0.7887\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4081 - accuracy: 0.8069 - val_loss: 0.6856 - val_accuracy: 0.7681\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4099 - accuracy: 0.8048 - val_loss: 0.7130 - val_accuracy: 0.7756\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3971 - accuracy: 0.8108 - val_loss: 0.6804 - val_accuracy: 0.7825\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3955 - accuracy: 0.8130 - val_loss: 0.6970 - val_accuracy: 0.7862\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3957 - accuracy: 0.8116 - val_loss: 0.7648 - val_accuracy: 0.7844\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3806 - accuracy: 0.8176 - val_loss: 0.7321 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3730 - accuracy: 0.8200 - val_loss: 0.7537 - val_accuracy: 0.7756\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3794 - accuracy: 0.8182 - val_loss: 0.7349 - val_accuracy: 0.7825\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3826 - accuracy: 0.8165 - val_loss: 0.7563 - val_accuracy: 0.7638\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3713 - accuracy: 0.8227 - val_loss: 0.8005 - val_accuracy: 0.7725\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3730 - accuracy: 0.8188 - val_loss: 0.7978 - val_accuracy: 0.7781\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3729 - accuracy: 0.8148 - val_loss: 0.8361 - val_accuracy: 0.7700\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3670 - accuracy: 0.8200 - val_loss: 0.8433 - val_accuracy: 0.7806\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3769 - accuracy: 0.8170 - val_loss: 0.8620 - val_accuracy: 0.7669\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3622 - accuracy: 0.8229 - val_loss: 0.8150 - val_accuracy: 0.7675\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3623 - accuracy: 0.8205 - val_loss: 0.8002 - val_accuracy: 0.7631\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.3563 - accuracy: 0.8259 - val_loss: 0.8494 - val_accuracy: 0.7756\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.3542 - accuracy: 0.8247 - val_loss: 0.8679 - val_accuracy: 0.7688\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3540 - accuracy: 0.8255 - val_loss: 0.8506 - val_accuracy: 0.7675\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.3602 - accuracy: 0.8250 - val_loss: 0.8789 - val_accuracy: 0.7731\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3571 - accuracy: 0.8224 - val_loss: 0.9026 - val_accuracy: 0.7719\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3437 - accuracy: 0.8331 - val_loss: 0.9091 - val_accuracy: 0.7681\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3442 - accuracy: 0.8321 - val_loss: 0.9796 - val_accuracy: 0.7663\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3523 - accuracy: 0.8219 - val_loss: 0.9304 - val_accuracy: 0.7719\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3432 - accuracy: 0.8317 - val_loss: 0.9295 - val_accuracy: 0.7812\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3405 - accuracy: 0.8317 - val_loss: 0.9708 - val_accuracy: 0.7688\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3546 - accuracy: 0.8296 - val_loss: 0.8888 - val_accuracy: 0.7825\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3476 - accuracy: 0.8233 - val_loss: 1.0062 - val_accuracy: 0.7675\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3440 - accuracy: 0.8251 - val_loss: 1.0599 - val_accuracy: 0.7569\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3420 - accuracy: 0.8383 - val_loss: 1.0290 - val_accuracy: 0.7538\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3340 - accuracy: 0.8350 - val_loss: 1.0851 - val_accuracy: 0.7600\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3394 - accuracy: 0.8352 - val_loss: 1.0225 - val_accuracy: 0.7513\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3315 - accuracy: 0.8398 - val_loss: 1.0183 - val_accuracy: 0.7556\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3307 - accuracy: 0.8409 - val_loss: 1.0366 - val_accuracy: 0.7575\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3285 - accuracy: 0.8383 - val_loss: 0.9964 - val_accuracy: 0.7638\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3384 - accuracy: 0.8347 - val_loss: 1.0455 - val_accuracy: 0.7613\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3243 - accuracy: 0.8399 - val_loss: 1.0366 - val_accuracy: 0.7550\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3263 - accuracy: 0.8363 - val_loss: 1.0154 - val_accuracy: 0.7519\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.3253 - accuracy: 0.8379 - val_loss: 1.0812 - val_accuracy: 0.7594\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3051 - accuracy: 0.8542 - val_loss: 1.1381 - val_accuracy: 0.7444\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3135 - accuracy: 0.8421 - val_loss: 1.0534 - val_accuracy: 0.7631\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3134 - accuracy: 0.8431 - val_loss: 1.1068 - val_accuracy: 0.7606\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3062 - accuracy: 0.8504 - val_loss: 1.0636 - val_accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3167 - accuracy: 0.8504 - val_loss: 1.0306 - val_accuracy: 0.7581\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3016 - accuracy: 0.8543 - val_loss: 1.1286 - val_accuracy: 0.7506\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3098 - accuracy: 0.8495 - val_loss: 1.1713 - val_accuracy: 0.7544\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2997 - accuracy: 0.8537 - val_loss: 1.1853 - val_accuracy: 0.7581\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3052 - accuracy: 0.8513 - val_loss: 1.1257 - val_accuracy: 0.7525\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3005 - accuracy: 0.8537 - val_loss: 1.2792 - val_accuracy: 0.7350\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3029 - accuracy: 0.8522 - val_loss: 1.2338 - val_accuracy: 0.7387\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.2893 - accuracy: 0.8554 - val_loss: 1.3628 - val_accuracy: 0.7275\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2848 - accuracy: 0.8649 - val_loss: 1.3052 - val_accuracy: 0.7337\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2949 - accuracy: 0.8562 - val_loss: 1.3074 - val_accuracy: 0.7469\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2903 - accuracy: 0.8585 - val_loss: 1.3499 - val_accuracy: 0.7425\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2907 - accuracy: 0.8578 - val_loss: 1.3613 - val_accuracy: 0.7419\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2789 - accuracy: 0.8654 - val_loss: 1.3418 - val_accuracy: 0.7531\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.2808 - accuracy: 0.8654 - val_loss: 1.2504 - val_accuracy: 0.7437\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.2967 - accuracy: 0.8570 - val_loss: 1.2594 - val_accuracy: 0.7387\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2802 - accuracy: 0.8609 - val_loss: 1.2839 - val_accuracy: 0.7381\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2792 - accuracy: 0.8642 - val_loss: 1.4548 - val_accuracy: 0.7369\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2846 - accuracy: 0.8587 - val_loss: 1.2783 - val_accuracy: 0.7531\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2905 - accuracy: 0.8618 - val_loss: 1.2417 - val_accuracy: 0.7544\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2790 - accuracy: 0.8647 - val_loss: 1.3721 - val_accuracy: 0.7394\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2687 - accuracy: 0.8688 - val_loss: 1.3940 - val_accuracy: 0.7387\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.2746 - accuracy: 0.8694 - val_loss: 1.5295 - val_accuracy: 0.7362\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2802 - accuracy: 0.8603 - val_loss: 1.4668 - val_accuracy: 0.7425\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.2732 - accuracy: 0.8682 - val_loss: 1.4686 - val_accuracy: 0.7362\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.2773 - accuracy: 0.8646 - val_loss: 1.4870 - val_accuracy: 0.7269\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.2772 - accuracy: 0.8606 - val_loss: 1.4468 - val_accuracy: 0.7506\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.2665 - accuracy: 0.8691 - val_loss: 1.5131 - val_accuracy: 0.7319\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2629 - accuracy: 0.8761 - val_loss: 1.4575 - val_accuracy: 0.7387\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2749 - accuracy: 0.8657 - val_loss: 1.4353 - val_accuracy: 0.7225\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.2775 - accuracy: 0.8665 - val_loss: 1.4772 - val_accuracy: 0.7281\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.2676 - accuracy: 0.8743 - val_loss: 1.5263 - val_accuracy: 0.7306\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.2729 - accuracy: 0.8683 - val_loss: 1.5709 - val_accuracy: 0.7181\n",
      "Epoch 90/100\n",
      " 20/100 [=====>........................] - ETA: 1s - loss: 0.2732 - accuracy: 0.8691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m      4\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m      5\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val)\n\u001b[1;32m      6\u001b[0m                    )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev2022/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=64, epochs=100, \n",
    "                    validation_data=(X_val, y_val)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dev2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e897f6c8348a15612778fc749f737b9e416c6c6907586e79554bdab5bcafe0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
